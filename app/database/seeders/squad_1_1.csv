year,method,url,title,F1,EM,gpu,#gpu,tpu,#tpu,time,hw_gflops,time_sec,params,#epochs
2016,"Dynamic Coattention Networks (single model)",https://arxiv.org/pdf/1611.01604v4.pdf,"Dynamic Coattention Networks For Question Answering",75.9,66.2,,,,,,,,,
2017,MEMEN(singel model),https://arxiv.org/pdf/1707.09098v1.pdf,"MEMEN: Multi-layer Embedding with Memory Networks for Machine Comprehension",85.344,78.234,GeForce Titan X,1,,,5 hours,1.10E+04,18000,,
2017,MEMEN(ensemble model),https://arxiv.org/pdf/1707.09098v1.pdf,"MEMEN: Multi-layer Embedding with Memory Networks for Machine Comprehension",82.66,75.37,GeForce Titan X,1,,,22 hours,1.10E+04,79200,,
2016,"Multi-Perspective Matching(ensemble)",https://arxiv.org/pdf/1612.04211v1.pdf,"Multi-Perspective Context Matching for Machine Comprehension",81.257,73.765,,,,,,,,,
2016,"Multi-Perspective Matching(single model)",https://arxiv.org/pdf/1612.04211v1.pdf,"Multi-Perspective Context Matching for Machine Comprehension",78.784,70.387,,,,,,,,,
2017,"smarnet(single model)",https://arxiv.org/pdf/1710.02772v1.pdf,"Smarnet: Teaching Machines to Read and Comprehend Like Human",80.16,71.415,GeForce GTX 1080 Ti,1,,,14 hours,1.13E+04,50400,,
2017,"SEDT+BiDAF(single model)",https://arxiv.org/pdf/1703.00572v3.pdf,"Structural Embedding of Syntactic Trees for Machine Comprehension",77.971,68.478,GeForce GTX 1080,1,,,,8.87E+03,,,
2018,FABIR,https://arxiv.org/pdf/1810.09580v1.pdf,A Fully Attention-Based Information Retriever,77.605,67.744,GeForce Titan X,1,,,,1.10E+04,,,54
2018,MAMCN+ ,https://www.aclweb.org/anthology/W18-2603.pdf,A Multi-Stage Memory Augmented Neural Network for Machine Reading Comprehension,86.727,79.692,,,,,,,,,12
2018,BERT (ensemble),https://arxiv.org/pdf/1810.04805v2.pdf,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,93.16,87.433,,,Cloud TPU v3,64,4 days,420000,345600,340000000,3
2018,BERT (single),https://arxiv.org/pdf/1810.04805v2.pdf,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,91.835,85.083,,,Cloud TPU v3,64,4 days,420000,345600,340000000,3
2016,"BiDAF(ensemble)",https://arxiv.org/pdf/1611.01603v6.pdf,Bidirectional Attention Flow for Machine Comprehension,81.525,73.744,GeForce Titan X,1,,,20 hours,1.10E+04,72000,,
2016,"BiDAF(single model)",https://arxiv.org/pdf/1611.01603v6.pdf,Bidirectional Attention Flow for Machine Comprehension,77.323,67.974,GeForce Titan X,1,,,20 hours,1.10E+04,72000,,
2017,"RaSoR + TR + LM(single model)",https://arxiv.org/pdf/1712.03609v4.pdf,Contextualized Word Representations for Reading Comprehension,84.163,77.583,,,,,,,,,
2017,"RaSoR + TR(single model)",https://arxiv.org/pdf/1712.03609v4.pdf,Contextualized Word Representations for Reading Comprehension,83.261,75.789,,,,,,,,,
2017,DCN+(ensemble),https://arxiv.org/pdf/1711.00106v2.pdf,DCN+: Mixed Objective and Deep Residual Coattention for Question Answering,85.996,78.852,,,,,,,,,
2017,DCN+(ensemble),https://arxiv.org/pdf/1711.00106v2.pdf,DCN+: Mixed Objective and Deep Residual Coattention for Question Answering,82.806,74.866,,,,,,,,,
2018,BiDAF + Self Attention + ELMo ,https://arxiv.org/pdf/1802.05365v2.pdf,Deep contextualized word representations,87.432,81.003,,,,,,,,,
2018,"BiDAF + Self Attention + ELMo (single model)",https://arxiv.org/pdf/1802.05365v2.pdf,Deep contextualized word representations,85.833,78.58,,,,,,,,,
2016,"Dynamic Coattention Networks(ensemble)",https://arxiv.org/pdf/1611.01604v4.pdf,Dynamic Coattention Networks For Question Answering,80.383,71.625,,,,,,,,,
2016,Dynamic Chunk Reader,https://arxiv.org/pdf/1610.09996v2.pdf,End-to-End Answer Chunk Extraction and Ranking for Reading Comprehension,70.956,62.499,,,,,,,,,40
2018,"KAR(single model)",https://arxiv.org/pdf/1809.03449v3.pdf,Explicit Utilization of General Knowledge in Machine Reading Comprehension,83.538,76.125,,,,,,,,,
2017,"jNet(ensemble)",https://arxiv.org/pdf/1703.04617v2.pdf,Exploring Question Understanding and Adaptation in Neural-Network-Based Question Answering,81.517,73.01,,,,,,,,,
2017,"jNet(single model)",https://arxiv.org/pdf/1703.04617v2.pdf,Exploring Question Understanding and Adaptation in Neural-Network-Based Question Answering,79.821,70.607,,,,,,,,,
2017,FusionNet(ensemble),https://arxiv.org/pdf/1711.07341v2.pdf,FusionNet: Fusing via Fully-Aware Attention with Application to Machine Comprehension,86.016,78.978,GeForce GTX Titan X,1,,,20 minutes per epcoh,,,,
2017,"FusionNet(single model)",https://arxiv.org/pdf/1711.07341v2.pdf,FusionNet: Fusing via Fully-Aware Attention with Application to Machine Comprehension,83.9,75.968,GeForce GTX Titan X,1,,,580 mins,6.60E+03,34800,,29
2017,"r-net(single model)",https://www.aclweb.org/anthology/P17-1018.pdf,Gated Self-Matching Networks for Reading Comprehension and Question Answering,84.265,76.461,,,,,,,,,
2017,DCN + Char + CoVe,https://arxiv.org/pdf/1708.00107v2.pdf,Learned in Translation: Contextualized Word Vectors,79.9,71.3,,,,,,,,,
2016,"RaSoR(single model)",https://arxiv.org/pdf/1611.01436v2.pdf,Learning Recurrent Span Representations for Extractive Question Answering,78.741,70.849,,,,,,,,,
2017,"OTF dict+spelling(single)",https://arxiv.org/pdf/1706.00286v3.pdf,Learning to Compute Word Embeddings On the Fly,73.056,64.083,,,,,,,,,
2017,"OTF spelling(single)",https://arxiv.org/pdf/1706.00286v3.pdf,Learning to Compute Word Embeddings On the Fly,72.016,62.897,,,,,,,,,
2017,"OTF spelling+lemma(single)",https://arxiv.org/pdf/1706.00286v3.pdf,Learning to Compute Word Embeddings On the Fly,71.968,62.604,,,,,,,,,
2016,"Match-LSTM with Ans-Ptr(Boundary)",https://arxiv.org/pdf/1608.07905v2.pdf,Machine Comprehension Using Match-LSTM and Answer Pointer,77.022,67.901,,,,,,,,,
2016,"Match-LSTM with Bi-Ans-Ptr(Boundary)",https://arxiv.org/pdf/1608.07905v2.pdf,Machine Comprehension Using Match-LSTM and Answer Pointer,73.743,64.744,,,,,,,,,
2016,"Match-LSTM with Ans-Ptr(Boundary)",https://arxiv.org/pdf/1608.07905v2.pdf,Machine Comprehension Using Match-LSTM and Answer Pointer,70.695,60.474,,,,,,,,,
2016,"Match-LSTM with Ans-Ptr(Sentence)",https://arxiv.org/pdf/1608.07905v2.pdf,Machine Comprehension Using Match-LSTM and Answer Pointer,67.748,54.505,,,,,,,,,
2017,FastQAExt,https://arxiv.org/pdf/1703.04816v3.pdf,Making Neural QA as Simple as Possible but not Simpler,78.857,70.849,,,,,,,,,
2017,FastQA,https://arxiv.org/pdf/1703.04816v3.pdf,Making Neural QA as Simple as Possible but not Simpler,77.07,68.436,,,,,,,,,
2017,,https://arxiv.org/pdf/1710.10504v2.pdf,Phase Conductor on Multi-layered Attentions for Machine Comprehension,84,76.1,,,,,,,,,
2017,"Conductor-net(single model)",https://arxiv.org/pdf/1710.10504v2.pdf,Phase Conductor on Multi-layered Attentions for Machine Comprehension,82.742,74.405,,,,,,,,,
2017,"Conductor-net(single)",https://arxiv.org/pdf/1710.10504v2.pdf,Phase Conductor on Multi-layered Attentions for Machine Comprehension,81.933,73.24,,,,,,,,,
2018,"QANet",https://arxiv.org/pdf/1804.09541v1.pdf,QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension,82.7,76.2,Tesla P100 PCIe 16 GB,1,,,18 hours,9.53E+03,64800,,
2017,"Document Reader(single model)",https://arxiv.org/pdf/1704.00051v2.pdf,Reading Wikipedia to Answer Open-Domain Questions,79,70,,,,,,,,,
2016,"ReasoNet(ensemble)",https://arxiv.org/pdf/1609.05284v3.pdf,ReasoNet: Learning to Stop Reading in Machine Comprehension,81.8,75.034,GeForce Titan X,1,,,12 hours,1.10E+04,43200,,18
2016,"ReasoNet(single model)",https://arxiv.org/pdf/1609.05284v3.pdf,ReasoNet: Learning to Stop Reading in Machine Comprehension,78.9,70.555,GeForce Titan X,1,,,12 hours,1.10E+04,43200,,18
2017,Reinforced Mnemonic Reader (ensemble),https://arxiv.org/pdf/1705.02798v6.pdf,Reinforced Mnemonic Reader for Machine Reading Comprehension,88.5,82.3,,,,,,,,,
2017,Reinforced Mnemonic Reader (single model),https://arxiv.org/pdf/1705.02798v6.pdf,Reinforced Mnemonic Reader for Machine Reading Comprehension,86.6,79.5,,,,,,,,,
2017,"Mnemonic Reader(ensemble)",https://arxiv.org/pdf/1705.02798v6.pdf,Reinforced Mnemonic Reader for Machine Reading Comprehension,82.371,74.268,,,,,,,,,
2017,"Mnemonic Reader(single model)",https://arxiv.org/pdf/1705.02798v6.pdf,Reinforced Mnemonic Reader for Machine Reading Comprehension,80.146,70.995,,,,,,,,,
2017,"Ruminating Reader(single model)",https://arxiv.org/pdf/1704.07415v1.pdf,Ruminating Reader: Reasoning with Gated Multi-Hop Attention,79.456,70.639,Tesla K80,1,,,2 days,5.60E+03,172800,,
2017,"BiDAF + Self Attention(single model)",https://arxiv.org/pdf/1710.10723v2.pdf,Simple and Effective Multi-Paragraph Reading Comprehension,81.048,72.139,,,,,,,,,
2017,SRU,https://arxiv.org/pdf/1709.02755v5.pdf,Simple Recurrent Units for Highly Parallelizable Recurrence,80.2,71.4,Tesla V100 PCIe 32 GB,1,,,3.5 days,1.41E+04,302400,,40
2019,SpanBERT,https://arxiv.org/pdf/1907.10529v2.pdf,SpanBERT: Improving Pre-training by Representing and Predicting Spans,94.6,88.8,Tesla V100 PCIe 32 GB,32,,,15 days,4.52E+05,1296000,340000000,4
2017,SAN,https://arxiv.org/pdf/1712.03556v2.pdf,Stochastic Answer Networks for Machine Reading Comprehension,86.496,79.608,GeForce Titan X,1,,,24 minutes per epoch,1.10E+04,18000,,12.5
2017,SAN(single model),https://arxiv.org/pdf/1712.03556v2.pdf,Stochastic Answer Networks for Machine Reading Comprehension,84.396,76.828,GeForce Titan X,1,,,24 minutes per epoch,1.10E+04,18000,,12.5
2017,"SEDT(ensemble model)",https://arxiv.org/pdf/1703.00572v3.pdf,Structural Embedding of Syntactic Trees for Machine Comprehension,81.761,74.09,GeForce GTX 1080,1,,,,8.87E+03,,,
2017,"SEDT+BiDAF(ensemble)",https://arxiv.org/pdf/1703.00572v3.pdf,Structural Embedding of Syntactic Trees for Machine Comprehension,81.53,73.723,GeForce GTX 1080,1,,,,8.87E+03,,,
2017,SEDT(single model),https://arxiv.org/pdf/1703.00572v3.pdf,Structural Embedding of Syntactic Trees for Machine Comprehension,77.527,68.163,GeForce GTX 1080,1,,,,8.87E+03,,,
2016,Fine-Grained Gating,https://arxiv.org/pdf/1611.01724v2.pdf,Words or Characters? Fine-grained Gating for Reading Comprehension,73.327,62.446,,,,,,,,,
2019,BiDAF,https://arxiv.org/pdf/1906.08237v1.pdf,XLNet: Generalized Autoregressive Pretraining for Language Understanding,95.08,89.9,,,Cloud TPU v3,512,2.5 days,2.15E+08,216000,,